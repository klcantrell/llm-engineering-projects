{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI (Artificial Intelligence) has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as articles, social media posts, product descriptions, and more, at scale and speed, reducing the need for human writers.\n",
      "2. **Image and Video Generation**: Generative AI can produce realistic images and videos, allowing businesses to create engaging visuals for marketing, advertising, and entertainment purposes.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI-powered chatbots can engage with customers, provide customer support, and answer frequently asked questions, freeing up human resources for more complex issues.\n",
      "4. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and equipment to predict maintenance needs, reducing downtime and increasing overall efficiency.\n",
      "5. **Product Design and Development**: Generative AI can help design new products, such as 3D models, prototypes, and even entire product lines, streamlining the product development process.\n",
      "6. **Marketing Automation**: Generative AI can personalize marketing campaigns, suggest product recommendations, and optimize advertising channels for better ROI.\n",
      "7. **Financial Analysis and Forecasting**: Generative AI can analyze large datasets to identify trends, predict market movements, and provide financial insights, helping businesses make informed decisions.\n",
      "8. **Customer Segmentation and Targeting**: Generative AI can segment customers based on their behavior, preferences, and demographics, enabling targeted marketing campaigns and improved customer engagement.\n",
      "9. **Language Translation and Localization**: Generative AI can translate text and audio in real-time, facilitating global communication and business expansion.\n",
      "10. **Creative Writing and Storytelling**: Generative AI can generate creative writing, such as poetry or short stories, and even entire scripts for films or plays.\n",
      "\n",
      "Some notable businesses that have adopted generative AI include:\n",
      "\n",
      "* Amazon (using generative AI to personalize product recommendations)\n",
      "* IBM (utilizing generative AI to analyze customer data and improve customer service)\n",
      "* Microsoft (leveraging generative AI to create personalized content and advertising)\n",
      "* Netflix (using generative AI to recommend movies and TV shows)\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as blog posts, social media posts, product descriptions, and even entire articles. This technology can help businesses save time and resources while improving the quality of their content.\n",
      "2. **Marketing Automation**: Generative AI can be used to create personalized marketing messages, offers, and campaigns tailored to specific customer segments. It can also help automate repetitive tasks such as email sending and lead generation.\n",
      "3. **Product Design**: Generative AI can assist in designing new products, packaging, and branding by generating ideas based on customer feedback, market trends, and product requirements.\n",
      "4. **Image and Video Generation**: Generative AI can create high-quality images and videos for various applications such as advertising, e-commerce, and entertainment. It can also help generate realistic simulations of real-world environments.\n",
      "5. **Customer Service Chatbots**: Generative AI-powered chatbots can provide 24/7 customer support, answer frequently asked questions, and route complex queries to human representatives.\n",
      "6. **Predictive Analytics**: Generative AI can analyze large datasets to predict customer behavior, detect patterns, and identify potential risks. This technology can help businesses make data-driven decisions and improve their risk management strategies.\n",
      "7. **Data Augmentation**: Generative AI can generate new, synthetic data that can be used to augment existing datasets, helping businesses to train and validate their machine learning models more effectively.\n",
      "8. **Personalization**: Generative AI can analyze customer behavior and preferences to create personalized experiences across various touchpoints such as websites, mobile apps, and social media platforms.\n",
      "9. **Document Generation**: Generative AI can generate official documents such as contracts, invoices, and receipts, saving businesses time and resources while improving the accuracy of their documentation.\n",
      "10. **Supply Chain Optimization**: Generative AI can analyze data from supply chain operations to predict demand, optimize inventory levels, and identify potential bottlenecks in the production process.\n",
      "\n",
      "Some specific examples of business applications of Generative AI include:\n",
      "\n",
      "* **Netflix's Content Recommendation Engine**: Uses generative AI to recommend TV shows and movies based on user preferences.\n",
      "* **DHL's Automated Logistics System**: Uses generative AI to optimize logistics operations and predict demand for shipping services.\n",
      "* **Amazon's Product Recommendations**: Uses generative AI to personalize product recommendations for customers based on their purchase history and browsing behavior.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As this technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: AI-powered tools can generate high-quality content such as articles, social media posts, and product descriptions, saving time and resources for businesses.\n",
      "2. **Virtual Assistants**: Chatbots and virtual assistants powered by Generative AI can provide 24/7 customer support, helping businesses improve customer engagement and reduce support costs.\n",
      "3. **Sales and Marketing Automation**: AI-powered content generation tools can create personalized marketing materials, such as emails, social media posts, and product demos, increasing the impact of marketing campaigns.\n",
      "4. **Creative Writing and Design**: Generative AI algorithms can assist writers in generating ideas, outlines, and even entire drafts, while also creating unique designs for visual content such as graphics, logos, and infographics.\n",
      "5. **Business Intelligence and Analytics**: AI-powered tools can analyze large datasets and generate insights, identifying trends, patterns, and correlations that inform business strategy and drive decision-making.\n",
      "6. **Predictive Maintenance and Quality Control**: Generative AI can help predict equipment failures and quality control defects by analyzing sensor data, reducing downtime and improving overall efficiency.\n",
      "7. **Customer Service Chatbots**: AI-powered chatbots can simulate human-like conversations, helping businesses personalize customer experience and resolve issues more effectively.\n",
      "8. **Digital Transformation and Innovation**: Generative AI enables businesses to explore new product development, service creation, and business model innovations by automating the design and testing of ideas.\n",
      "9. **Personalized Experience and Recommendations**: Businesses can use Generative AI to analyze customer data and create customized experiences, such as personalized product recommendations and tailored content offers.\n",
      "10. **Supply Chain Optimization**: AI-powered tools can predict demand, optimize inventory levels, and simulate scenarios to prevent disruptions in supply chains, improving overall operational efficiency.\n",
      "\n",
      "Some specific examples of businesses that are leveraging Generative AI include:\n",
      "\n",
      "* **Salesforc*e**: Using AI-powered chatbots to power customer support and engagement\n",
      "* **Uber**: Implementing Generative AI-powered tools for route optimization and demand forecasting\n",
      "* **Accenture**: Developing a digital transformation platform powered by Generative AI\n",
      "* **Amazon**: Utilizing AI-powered tools to personalize product recommendations and improve customer experience\n",
      "\n",
      "These are just a few examples of the many businesses that are exploring the potential of Generative AI to drive innovation, efficiency, and customer satisfaction.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the main concepts that underpin Learning to Learn (LLMs) with Neural Networks. I'm not exactly sure what an LLM is or how it all works, but from my readings and some basic searches, I recall there's a connection between deep learning models like neural networks and language models. \n",
      "\n",
      "Let me start by breaking down the user’s question: they're asking for definitions of:\n",
      "\n",
      "1. Core concepts behind Neural Networks\n",
      "2. Attention mechanism in transformers\n",
      "\n",
      "I think understanding LLMs would help because they rely on these neural network structures, right? So maybe I should explain what a Neural Network is first.\n",
      "\n",
      "A Neural Network... Okay, so neural networks are inspired by the human brain. They have layers of neurons that process information. Each neuron connects to others and processes input data through weights. In LLMs, these typically use multi-layer perceptrons (MLPs) or convolutional neural networks (CNNs). MLPs take a sequence as input, multiply each element with corresponding weights in the first layer, sum them up, and pass to the next layer. CNNs are better for images because they process squares sliding across an image.\n",
      "\n",
      "Wait, but LLMs use more advanced structures than regular NNs? I think they combine some of these. They might have attention mechanisms, maybe that's where \"attention\" in transformers comes from. So the core idea is using neural networks to learn representations and generate responses through multiple layers.\n",
      "\n",
      "So for Neural Networks: they're a series of interconnected neurons processing data through layers. They use weights (parameters) to model connections between these processes. They have hidden layers, nonlinearities (like ReLU or tanh), activation functions, dropout for regularization, and often gradient descent optimization methods like Adam to train the model.\n",
      "\n",
      "Now attention mechanisms specifically in transformers. I remember there's something about focusing on important parts of the input. In traditional neural networks, we process all features without any awareness of what's relevant. But in models used for language tasks (like LLMs), each token in a sequence can attend to other tokens that are \"important\" based on their context. This is called attention since it allows model parts to focus on different points.\n",
      "\n",
      "How does this work? The model computes attention scores between all pairs of input tokens, which determines how much the output should respond to each input. After computing these attention weights, each token's output is a weighted sum of its own and others' embeddings, where weights are those matrices (matrices MxM, maybe?) scaled by some hyperparameters like temperature.\n",
      "\n",
      "Wait, but in an LLM context, what would be important? I think it's learning local structures, which helps capture context. Unlike typical NNs that handle global information well if the dataset is large enough, local structure helps manage when small datasets are available because you don't need to rely on entire sentences or paragraphs.\n",
      "\n",
      "So the focus is not on global features but local ones, allowing the model to adapt quickly even with limited data. That makes sense for handling sparse data which traditional text models often struggle with, especially in few-shot learning scenarios where examples are scarce.\n",
      "\n",
      "Now putting it all together: LLMs use deep neural networks with attention mechanisms to adaptively focus on relevant parts of input data. This helps them perform well on small datasets without relying too much on global patterns. So the core concept is using neural networks that process sequences, employing layers for higher processing and attention for context-aware understanding.\n",
      "\n",
      "I think I have a rough idea now. To structure it clearly:\n",
      "\n",
      "1. Define Neural Networks:\n",
      "   - Inspired by biological neurons.\n",
      "   - Layers (input, hidden, output).\n",
      "   - Parameters, weights.\n",
      "   - Without self-attention usually, but with mechanisms that could change this later.\n",
      "   - Often used without attention first, then adding attention to enable local processing.\n",
      "\n",
      "2. Attention in Transformers:\n",
      "   - Allows models to focus on relevant parts of input.\n",
      "   - Computed based on the model's weight matrices.\n",
      "   - Informs the order and importance of text tokens or sequences.\n",
      "\n",
      "3. How these lead to LLMs:\n",
      "   - Use neural networks with attention for localized features.\n",
      "   - Enable adaptively focusing, which helps in sparse data.\n",
      "   - Provides a way to handle large models without local context but can scale up while maintaining effectiveness, especially with few training examples.\n",
      "\n",
      "I might have missed some details or assumptions here. Let me think if there are more points to cover regarding training and efficiency of these structures.\n",
      "\n",
      "In LLMs, the sequential processing and attention based on context could lead them efficiently handle tasks where global patterns aren't feasible. The use of local structures also ties into why they can become faster during training (lower memory footprint) due to reduced global computation.\n",
      "\n",
      "Maybe I should also mention that these models are different from traditional NLP models because of their adaptability, self-attention capabilities, and efficient inference when dealing with limited data. That could be a key point for the user's question about core concepts behind LLMs.\n",
      "\n",
      "Yes, so the main points would tie together the neural network framework, the specific attention mechanism in transformers enabling focused processing, and how this combination makes LLMs more adaptable and efficient than traditional approaches.\n",
      "</think>\n",
      "\n",
      "**Core Concepts Behind Learning to Learn (LLMs) Using Neural Networks**\n",
      "\n",
      "1. **Neural Networks:**\n",
      "   - **Inspiration:** Drawing from biological neurons, neural networks process data through interconnected layers inspired by the brain.\n",
      "   - **Layers:** Comprises input, hidden, and output layers, where each layer processes data through weights and biases to produce outputs.\n",
      "   - **Parameters:** Weights and biases are trainable parameters determining processing strength.\n",
      "   - **Activation Functions & Regularization:** Nonlinearities (e.g., ReLU) facilitate learning, with dropout for regularization against overfitting.\n",
      "   - **Training:** Typically employs methods like stochastic gradient descent without initial self-attention, which can later be enhanced.\n",
      "\n",
      "2. **Attention Mechanism in Transformers:**\n",
      "   - **Focal Processing:** Introduces mechanisms to focus on relevant input parts, crucial for contextual understanding.\n",
      "   - **Score Computation:** Determines how much attention each token contributes by considering connections between its embedding and others'.\n",
      "   - **Output Generation:** Produces an output that is a weighted sum of the current and connected tokens' embeddings.\n",
      "\n",
      "3. **LLMs and Their Design:**\n",
      "   - **Sequential Processing & Attention:** Deep neural networks process inputs sequentially, employing self-attention to enable local context consideration.\n",
      "   - **Adaptability and Efficiency:** Enable quick learning from limited data, avoiding reliance on bulky global patterns found in large datasets.\n",
      "   - **Efficient Inference:** Reduced computational complexity during training due to focus on relevant processing.\n",
      "\n",
      "In summary, LLMs leverage neural networks with attention mechanisms to focus on local structures, making them more adaptable and efficient than traditional NLP models, especially suited for scenarios with scarce data.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This is a recipe for traditional Hawaiian-Style Spam Musubi, which is a popular snack in Hawaii and around the world.\n",
       "\n",
       "The ingredient list includes:\n",
       "\n",
       "* 8 slices of reduced-salt Spam\n",
       "* 1 cup of Japanese short-grain rice\n",
       "* Sesame oil\n",
       "* Soy sauce (optional)\n",
       "* Sugar\n",
       "* Rice vinegar\n",
       "\n",
       "Instructions:\n",
       "\n",
       "1. Prepare the rice according to package instructions.\n",
       "2. Cut the Spam into thin slices.\n",
       "3. Brush the sesame oil onto a small portion of the nori seaweed, which will be used as the wrapping material for the musubi.\n",
       "4. Place a block of rice on top of the nori sheet.\n",
       "5. Add a slice of Spam to the rice block.\n",
       "6. Fold the sides of the nori sheet over the rice and Spam, and then roll it up into a tight cylinder.\n",
       "7. Repeat with the remaining ingredients.\n",
       "\n",
       "The author notes that the recipe is relatively easy and can be stored in the refrigerator for up to 4 days or frozen for later use.\n",
       "\n",
       "Nutritional information per serving:\n",
       "\n",
       "* Calories: 317\n",
       "* Carbohydrates: 43g\n",
       "* Protein: 9g\n",
       "* Fat: 12g\n",
       "* Saturated fat: 4g\n",
       "* Cholesterol: 30mg\n",
       "* Sodium: 1210mg\n",
       "* Potassium: 202mg\n",
       "* Fiber: 1g\n",
       "* Sugar: 13g\n",
       "* Calcium: 6mg\n",
       "* Iron: 0.6mg\n",
       "\n",
       "Overall, this recipe appears to be a classic and delicious example of Spam musubi, with a brief explanation of the ingredients and process required to make it."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n",
    "\n",
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"Your job is to extract the ingredients list from a food recipe website. \\\n",
    "Only include the list of ingredients in your response. \\\n",
    "Don't include any explanations in your response, just the ingredients.\"\n",
    "\n",
    "def user_recipe_prompt_for(website):\n",
    "    user_prompt = \"What ingredients do I need to cook this recipe?\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for_recipe(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_recipe_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "def extract_recipe(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_for_recipe(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def display_recipe(url):\n",
    "    summary = extract_recipe(url)\n",
    "    display(Markdown(summary))\n",
    "    \n",
    "\n",
    "# Step 2: Call OpenAI\n",
    "\n",
    "response = display_recipe('https://www.favfamilyrecipes.com/musubi/')\n",
    "\n",
    "# Step 3: print the result\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508bf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
